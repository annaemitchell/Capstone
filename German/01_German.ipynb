{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project, by Anna Mitchell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation\n",
    "### English to German "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code help and adaption for this project come from the following resources:\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/\n",
    "#https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
    "#https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "#https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/\n",
    "#https://google.github.io/seq2seq/nmt/\n",
    "#https://opennmt.net/\n",
    "#https://stackoverflow.com/questions/tagged/machine-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "# load data to preserve unicode german characters, loads file as a blob of text\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "# remove non printable characters\n",
    "# remove all punctuation characters\n",
    "# normalize all unicode characters to ASCII\n",
    "#normalize the case to lower\n",
    "#remove any remaining tokens that are not alphabetic \n",
    "#perform these operations on each phrase for each pair in the loaded dataset.\n",
    "\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list of clean sentences to file\n",
    "def clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Source: http://www.manythings.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german.pkl\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "filename = 'deu1.txt'\n",
    "doc = load_doc(filename)\n",
    "# split into english-german pairs\n",
    "pairs = pairs(doc)\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "# save clean pairs to file\n",
    "clean_data(clean_pairs, 'english-german.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[go] => [geh]\n",
      "[hi] => [hallo]\n",
      "[hi] => [gru gott]\n",
      "[run] => [lauf]\n",
      "[run] => [lauf]\n",
      "[wow] => [potzdonner]\n",
      "[wow] => [donnerwetter]\n",
      "[fire] => [feuer]\n",
      "[help] => [hilfe]\n",
      "[help] => [zu hulf]\n",
      "[stop] => [stopp]\n",
      "[wait] => [warte]\n",
      "[wait] => [warte]\n",
      "[begin] => [fang an]\n",
      "[go on] => [mach weiter]\n",
      "[hello] => [hallo]\n",
      "[hurry] => [beeil dich]\n",
      "[hurry] => [schnell]\n",
      "[i hid] => [ich versteckte mich]\n",
      "[i hid] => [ich habe mich versteckt]\n",
      "[i ran] => [ich rannte]\n",
      "[i see] => [ich verstehe]\n",
      "[i see] => [aha]\n",
      "[i try] => [ich probiere es]\n",
      "[i won] => [ich hab gewonnen]\n",
      "[i won] => [ich habe gewonnen]\n",
      "[relax] => [entspann dich]\n",
      "[shoot] => [feuer]\n",
      "[shoot] => [schie]\n",
      "[smile] => [lacheln]\n",
      "[ask me] => [frag mich]\n",
      "[ask me] => [fragt mich]\n",
      "[ask me] => [fragen sie mich]\n",
      "[attack] => [angriff]\n",
      "[attack] => [attacke]\n",
      "[cheers] => [zum wohl]\n",
      "[eat it] => [iss es]\n",
      "[eat up] => [iss auf]\n",
      "[eat up] => [iss auf]\n",
      "[freeze] => [keine bewegung]\n",
      "[freeze] => [stehenbleiben]\n",
      "[go now] => [geh jetzt]\n",
      "[got it] => [verstanden]\n",
      "[got it] => [aha]\n",
      "[got it] => [ich habs]\n",
      "[got it] => [kapiert]\n",
      "[got it] => [verstanden]\n",
      "[got it] => [einverstanden]\n",
      "[he ran] => [er rannte]\n",
      "[he ran] => [er lief]\n"
     ]
    }
   ],
   "source": [
    "# check if working\n",
    "for i in range(50):\n",
    "    print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german-both.pkl\n",
      "Saved: english-german-train.pkl\n",
      "Saved: english-german-test.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "raw_dataset = load_clean_sentences('english-german.pkl')\n",
    "\n",
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test\n",
    "train, test = dataset[:9000], dataset[9000:]\n",
    "# save\n",
    "clean_data(dataset, 'english-german-both.pkl')\n",
    "clean_data(train, 'english-german-train.pkl')\n",
    "clean_data(test, 'english-german-test.pkl')\n",
    "\n",
    "#both.pkl - contains all of the train and test examples that we can use to \n",
    "#-> define the parameters of the problem, such a smax phrase lengths and the vocab\n",
    "# train.pkl and test.pkl - train and test dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to Sequence Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu1.txt\")\n",
    "ger_eng = to_lines(data)\n",
    "ger_eng = array(ger_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_eng = ger_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "ger_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in ger_eng[:,0]]\n",
    "ger_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in ger_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(ger_eng)):\n",
    "    ger_eng[i,0] = ger_eng[i,0].lower()\n",
    "    \n",
    "    ger_eng[i,1] = ger_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "ger_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in ger_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in ger_eng[:,1]:\n",
    "    ger_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'english':eng_l, 'german':ger_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum length of German: 11\n",
    "#Maxiumum lenght of English: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6243\n"
     ]
    }
   ],
   "source": [
    "# english tokenizer\n",
    "eng_tokenizer = tokenization(ger_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Vocabulary Size: 10329\n"
     ]
    }
   ],
   "source": [
    "# German tokenizer\n",
    "ger_tokenizer = tokenization(ger_eng[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "\n",
    "ger_length = 8\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#develop neural translation model\n",
    "#load and prepare clean text data ready for modeling and define and train the model\n",
    "#-> on the prepared data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://medium.com/@umerfarooq_26378/neural-machine-translation-with-code-68c425044bbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 2241\n",
      "English Max Length: 5\n",
      "German Vocabulary Size: 3572\n",
      "German Max Length: 9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 9, 256)            914432    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 2241)           575937    \n",
      "=================================================================\n",
      "Total params: 2,540,993\n",
      "Trainable params: 2,540,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.41482, saving model to model.h5\n",
      "141/141 - 11s - loss: 4.1500 - val_loss: 3.4148\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.41482 to 3.27463, saving model to model.h5\n",
      "141/141 - 9s - loss: 3.2227 - val_loss: 3.2746\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.27463 to 3.18043, saving model to model.h5\n",
      "141/141 - 9s - loss: 3.0891 - val_loss: 3.1804\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.18043 to 3.05110, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.9525 - val_loss: 3.0511\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.05110 to 2.95380, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.8015 - val_loss: 2.9538\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.95380 to 2.89567, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.6698 - val_loss: 2.8957\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.89567 to 2.79843, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.5576 - val_loss: 2.7984\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.79843 to 2.71061, saving model to model.h5\n",
      "141/141 - 9s - loss: 2.4318 - val_loss: 2.7106\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.71061 to 2.62356, saving model to model.h5\n",
      "141/141 - 9s - loss: 2.3053 - val_loss: 2.6236\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.62356 to 2.55755, saving model to model.h5\n",
      "141/141 - 9s - loss: 2.1815 - val_loss: 2.5576\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.55755 to 2.46752, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.0582 - val_loss: 2.4675\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.46752 to 2.40004, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.9387 - val_loss: 2.4000\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.40004 to 2.32302, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.8264 - val_loss: 2.3230\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.32302 to 2.26113, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.7147 - val_loss: 2.2611\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.26113 to 2.20293, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.6110 - val_loss: 2.2029\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.20293 to 2.15707, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.5091 - val_loss: 2.1571\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.15707 to 2.11485, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.4112 - val_loss: 2.1149\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.11485 to 2.06401, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.3175 - val_loss: 2.0640\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.06401 to 2.02771, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.2282 - val_loss: 2.0277\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.02771 to 1.99544, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.1406 - val_loss: 1.9954\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.99544 to 1.95977, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.0605 - val_loss: 1.9598\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.95977 to 1.94180, saving model to model.h5\n",
      "141/141 - 11s - loss: 0.9802 - val_loss: 1.9418\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.94180 to 1.91180, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.9041 - val_loss: 1.9118\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.91180 to 1.88977, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.8339 - val_loss: 1.8898\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.88977 to 1.88435, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.7669 - val_loss: 1.8843\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.88435 to 1.87008, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.7041 - val_loss: 1.8701\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.87008 to 1.85510, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.6482 - val_loss: 1.8551\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.85510 to 1.84017, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.5944 - val_loss: 1.8402\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.84017 to 1.82752, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.5433 - val_loss: 1.8275\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.82752\n",
      "141/141 - 9s - loss: 0.4997 - val_loss: 1.8349\n"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    " \n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    " \n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    " \n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    " \n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    " \n",
    "# load datasets\n",
    "dataset = load_clean_sentences('english-german-both.pkl')\n",
    "train = load_clean_sentences('english-german-train.pkl')\n",
    "test = load_clean_sentences('english-german-test.pkl')\n",
    " \n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
    "print('German Max Length: %d' % (ger_length))\n",
    " \n",
    "# prepare training data\n",
    "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "# prepare validation data\n",
    "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, eng_vocab_size)\n",
    " \n",
    "# define model\n",
    "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's compare the training loss and the validation loss.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Neural Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dataset = load_clean_sentences('english-german-both.pkl')\n",
    "train = load_clean_sentences('english-german-train.pkl')\n",
    "test = load_clean_sentences('english-german-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save my NN model to YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://towardsdatascience.com/saving-and-loading-keras-model-42195b92f57a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4289616048336029"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(trainX, trainY, verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.73%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(trainX, trainY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next repeat this for each source phrase in a dataset and \n",
    "#-> compare the predicted result to the expected target phrase in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from #https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "src=[hat tom gesungen], target=[did tom sing], predicted=[did tom sing]\n",
      "src=[ich bin sauer auf dich], target=[im mad at you], predicted=[im not school]\n",
      "src=[mache dich bereit zu sterben], target=[prepare to die], predicted=[get the]\n",
      "src=[sie konnen es versuchen], target=[you can try], predicted=[you can try]\n",
      "src=[das ist einfach], target=[this is simple], predicted=[thats is]\n",
      "src=[bist du gro], target=[are you tall], predicted=[are you tall]\n",
      "src=[sag es mir], target=[tell me], predicted=[tell me]\n",
      "src=[du hast nicht getroffen], target=[you missed], predicted=[you missed]\n",
      "src=[ich wusste das], target=[i knew that], predicted=[i knew this]\n",
      "src=[ich brauche mehr], target=[i need more], predicted=[i need more]\n",
      "BLEU-1: 0.848000\n",
      "BLEU-2: 0.788762\n",
      "BLEU-3: 0.680667\n",
      "BLEU-4: 0.362602\n",
      "test\n",
      "src=[tom lachelte], target=[tom smiled], predicted=[tom smiled]\n",
      "src=[sie sind wieder da], target=[theyre back], predicted=[theyre back]\n",
      "src=[setz dich], target=[sit down], predicted=[have a seat]\n",
      "src=[lass mich mal probieren], target=[let me try], predicted=[let me try]\n",
      "src=[bin ich geeignet], target=[am i qualified], predicted=[am i invited]\n",
      "src=[ich bin nicht beruhmt], target=[im not famous], predicted=[im not]\n",
      "src=[tom erstarrte], target=[tom froze], predicted=[tom answered]\n",
      "src=[ich bin engagiert], target=[im dedicated], predicted=[im interested]\n",
      "src=[offne den tresor], target=[open the safe], predicted=[open the gate]\n",
      "src=[mein hund ist braun], target=[my dogs brown], predicted=[he is is]\n",
      "BLEU-1: 0.538519\n",
      "BLEU-2: 0.406826\n",
      "BLEU-3: 0.318743\n",
      "BLEU-4: 0.123961\n"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    " \n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    " \n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    " \n",
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    " \n",
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    " \n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, eng_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    " \n",
    "# load datasets\n",
    "dataset = load_clean_sentences('english-german-both.pkl')\n",
    "train = load_clean_sentences('english-german-train.pkl')\n",
    "test = load_clean_sentences('english-german-test.pkl')\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "# prepare german tokenizer\n",
    "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
    "ger_length = max_length(dataset[:, 1])\n",
    "# prepare data\n",
    "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    " \n",
    "# load model\n",
    "model = load_model('model.h5')\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-193c8672be89>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tom smiled</td>\n",
       "      <td>tom smiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theyre back</td>\n",
       "      <td>theyre back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sit down</td>\n",
       "      <td>have a seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>let me try</td>\n",
       "      <td>let me try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>am i qualified</td>\n",
       "      <td>am i invited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>im not famous</td>\n",
       "      <td>im not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tom froze</td>\n",
       "      <td>tom answered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im dedicated</td>\n",
       "      <td>im interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open the safe</td>\n",
       "      <td>open the gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>my dogs brown</td>\n",
       "      <td>he is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>watch us</td>\n",
       "      <td>well you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tom is jittery</td>\n",
       "      <td>tom is nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get away</td>\n",
       "      <td>go away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>please go away</td>\n",
       "      <td>please relax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>im expecting</td>\n",
       "      <td>im not family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual         predicted\n",
       "0       tom smiled     tom smiled   \n",
       "1      theyre back    theyre back   \n",
       "2         sit down     have a seat  \n",
       "3       let me try      let me try  \n",
       "4   am i qualified    am i invited  \n",
       "5    im not famous         im not   \n",
       "6        tom froze   tom answered   \n",
       "7     im dedicated  im interested   \n",
       "8    open the safe   open the gate  \n",
       "9    my dogs brown          he is   \n",
       "10        watch us       well you   \n",
       "11  tom is jittery  tom is nervous  \n",
       "12        get away        go away   \n",
       "13  please go away   please relax   \n",
       "14    im expecting   im not family  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tom is unkind</td>\n",
       "      <td>tom is nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>tom was lying</td>\n",
       "      <td>tom knows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>tom confessed</td>\n",
       "      <td>tom has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>i have cash</td>\n",
       "      <td>i cried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>i like to sing</td>\n",
       "      <td>i like singing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>dont respond</td>\n",
       "      <td>dont laugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>were joking</td>\n",
       "      <td>were joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>ive found it</td>\n",
       "      <td>i found it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hang on a sec</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>lets dance</td>\n",
       "      <td>lets try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>get dressed</td>\n",
       "      <td>put us sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>unbelievable</td>\n",
       "      <td>dont get off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ill join you</td>\n",
       "      <td>im game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>i hate coffee</td>\n",
       "      <td>i hate sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>i read books</td>\n",
       "      <td>i like fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual         predicted\n",
       "53    tom is unkind     tom is nice  \n",
       "766   tom was lying      tom knows   \n",
       "868   tom confessed        tom has   \n",
       "647     i have cash        i cried   \n",
       "614  i like to sing  i like singing  \n",
       "142    dont respond     dont laugh   \n",
       "407     were joking    were joking   \n",
       "898    ive found it      i found it  \n",
       "348   hang on a sec            no    \n",
       "478      lets dance       lets try   \n",
       "806     get dressed    put us sleep  \n",
       "310    unbelievable    dont get off  \n",
       "164    ill join you        im game   \n",
       "332   i hate coffee     i hate sing  \n",
       "520    i read books    i like fruit  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
