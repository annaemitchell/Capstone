{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation\n",
    "### English to French "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code help and adaption for this project come from the following resources:\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/\n",
    "#https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
    "#https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "#https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/\n",
    "#https://google.github.io/seq2seq/nmt/\n",
    "#https://opennmt.net/\n",
    "#https://stackoverflow.com/questions/tagged/machine-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "# load data to preserve unicode french characters, loads file as a blob of text\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "#\n",
    "def pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "# remove non printable characters\n",
    "# remove all punctuation characters\n",
    "# normalize all unicode characters to ASCII\n",
    "#normalize the case to lower\n",
    "#remove any remaining tokens that are not alphabetic \n",
    "#perform these operations on each phrase for each pair in the loaded dataset.\n",
    "\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list of clean sentences to file\n",
    "def clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Source: http://www.manythings.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-french.pkl\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "filename = 'fre.txt'\n",
    "doc = load_doc(filename)\n",
    "# split into english-french pairs\n",
    "pairs = pairs(doc)\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "# save clean pairs to file\n",
    "clean_data(clean_pairs, 'english-french.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[go] => [va]\n",
      "[hi] => [salut]\n",
      "[hi] => [salut]\n",
      "[run] => [cours]\n",
      "[run] => [courez]\n",
      "[who] => [qui]\n",
      "[wow] => [ca alors]\n",
      "[fire] => [au feu]\n",
      "[help] => [a laide]\n",
      "[jump] => [saute]\n",
      "[stop] => [ca suffit]\n",
      "[stop] => [stop]\n",
      "[stop] => [arretetoi]\n",
      "[wait] => [attends]\n",
      "[wait] => [attendez]\n",
      "[go on] => [poursuis]\n",
      "[go on] => [continuez]\n",
      "[go on] => [poursuivez]\n",
      "[hello] => [bonjour]\n",
      "[hello] => [salut]\n",
      "[i see] => [je comprends]\n",
      "[i try] => [jessaye]\n",
      "[i won] => [jai gagne]\n",
      "[i won] => [je lai emporte]\n",
      "[i won] => [jai gagne]\n",
      "[oh no] => [oh non]\n",
      "[attack] => [attaque]\n",
      "[attack] => [attaquez]\n",
      "[cheers] => [sante]\n",
      "[cheers] => [a votre sante]\n",
      "[cheers] => [merci]\n",
      "[cheers] => [tchintchin]\n",
      "[get up] => [levetoi]\n",
      "[go now] => [va maintenant]\n",
      "[go now] => [allezy maintenant]\n",
      "[go now] => [vasy maintenant]\n",
      "[got it] => [jai pige]\n",
      "[got it] => [compris]\n",
      "[got it] => [pige]\n",
      "[got it] => [compris]\n",
      "[got it] => [tas capte]\n",
      "[hop in] => [monte]\n",
      "[hop in] => [montez]\n",
      "[hug me] => [serremoi dans tes bras]\n",
      "[hug me] => [serrezmoi dans vos bras]\n",
      "[i fell] => [je suis tombee]\n",
      "[i fell] => [je suis tombe]\n",
      "[i fled] => [jai fui]\n",
      "[i know] => [je sais]\n",
      "[i left] => [je suis parti]\n"
     ]
    }
   ],
   "source": [
    "# checking to make sure works\n",
    "for i in range(50):\n",
    "    print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-french-both.pkl\n",
      "Saved: english-french-train.pkl\n",
      "Saved: english-french-test.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "raw_dataset = load_clean_sentences('english-french.pkl')\n",
    "\n",
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test\n",
    "train, test = dataset[:9000], dataset[9000:]\n",
    "# save\n",
    "clean_data(dataset, 'english-french-both.pkl')\n",
    "clean_data(train, 'english-french-train.pkl')\n",
    "clean_data(test, 'english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to Sequence Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"fre.txt\")\n",
    "fre_eng = to_lines(data)\n",
    "fre_eng = array(fre_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_eng = fre_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "fre_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fre_eng[:,0]]\n",
    "fre_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fre_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(fre_eng)):\n",
    "    fre_eng[i,0] = fre_eng[i,0].lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "fre_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in fre_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in fre_eng[:,1]:\n",
    "    fre_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'english':eng_l, 'french':fre_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum length of French: 22?\n",
    "#Maxiumum lenght of English: 22?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6025\n"
     ]
    }
   ],
   "source": [
    "# english tokenizer\n",
    "eng_tokenizer = tokenization(fre_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Vocabulary Size: 13986\n"
     ]
    }
   ],
   "source": [
    "# french tokenizer\n",
    "fre_tokenizer = tokenization(fre_eng[:, 1])\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "\n",
    "fre_length = 8\n",
    "print('French Vocabulary Size: %d' % fre_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#develop neural translation model\n",
    "#load and prepare clean text data ready for modeling and define and train the model\n",
    "#-> on the prepared data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://medium.com/@umerfarooq_26378/neural-machine-translation-with-code-68c425044bbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 2158\n",
      "English Max Length: 5\n",
      "French Vocabulary Size: 4388\n",
      "French Max Length: 10\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 256)           1123328   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 5, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 2158)           554606    \n",
      "=================================================================\n",
      "Total params: 2,728,558\n",
      "Trainable params: 2,728,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.40263, saving model to model.h5\n",
      "141/141 - 11s - loss: 4.2048 - val_loss: 3.4026\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.40263 to 3.20519, saving model to model.h5\n",
      "141/141 - 11s - loss: 3.2437 - val_loss: 3.2052\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.20519 to 3.12040, saving model to model.h5\n",
      "141/141 - 10s - loss: 3.0769 - val_loss: 3.1204\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.12040 to 3.00513, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.9434 - val_loss: 3.0051\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.00513 to 2.87163, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.7639 - val_loss: 2.8716\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.87163 to 2.77680, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.6007 - val_loss: 2.7768\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.77680 to 2.67703, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.4465 - val_loss: 2.6770\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.67703 to 2.58840, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.3065 - val_loss: 2.5884\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.58840 to 2.50158, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.1734 - val_loss: 2.5016\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.50158 to 2.42994, saving model to model.h5\n",
      "141/141 - 10s - loss: 2.0443 - val_loss: 2.4299\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.42994 to 2.34526, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.9156 - val_loss: 2.3453\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.34526 to 2.28157, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.7914 - val_loss: 2.2816\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.28157 to 2.22472, saving model to model.h5\n",
      "141/141 - 10s - loss: 1.6785 - val_loss: 2.2247\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.22472 to 2.16858, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.5678 - val_loss: 2.1686\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.16858 to 2.11549, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.4632 - val_loss: 2.1155\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.11549 to 2.07816, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.3643 - val_loss: 2.0782\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.07816 to 2.04322, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.2684 - val_loss: 2.0432\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.04322 to 1.99417, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.1759 - val_loss: 1.9942\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.99417 to 1.97340, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.0860 - val_loss: 1.9734\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.97340 to 1.94119, saving model to model.h5\n",
      "141/141 - 9s - loss: 1.0041 - val_loss: 1.9412\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.94119 to 1.91008, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.9254 - val_loss: 1.9101\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.91008 to 1.89284, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.8490 - val_loss: 1.8928\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.89284 to 1.87284, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.7795 - val_loss: 1.8728\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.87284 to 1.84914, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.7116 - val_loss: 1.8491\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.84914 to 1.84058, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.6488 - val_loss: 1.8406\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.84058 to 1.82588, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.5906 - val_loss: 1.8259\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.82588 to 1.81581, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.5381 - val_loss: 1.8158\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.81581 to 1.79490, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.4911 - val_loss: 1.7949\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.79490 to 1.79053, saving model to model.h5\n",
      "141/141 - 9s - loss: 0.4480 - val_loss: 1.7905\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.79053\n",
      "141/141 - 9s - loss: 0.4054 - val_loss: 1.7938\n"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    " \n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    " \n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    " \n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    " \n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "\n",
    "# load datasets\n",
    "dataset = load_clean_sentences('english-french-both.pkl')\n",
    "train = load_clean_sentences('english-french-train.pkl')\n",
    "test = load_clean_sentences('english-french-test.pkl')\n",
    " \n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "# prepare french tokenizer\n",
    "fre_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "fre_length = max_length(dataset[:, 1])\n",
    "print('French Vocabulary Size: %d' % fre_vocab_size)\n",
    "print('French Max Length: %d' % (fre_length))\n",
    " \n",
    "# prepare training data\n",
    "trainX = encode_sequences(fre_tokenizer, fre_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "# prepare validation data\n",
    "testX = encode_sequences(fre_tokenizer, fre_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, eng_vocab_size)\n",
    " \n",
    "# define model\n",
    "model = define_model(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's compare the training loss and the validation loss.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Neural Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dataset = load_clean_sentences('english-french-both.pkl')\n",
    "train = load_clean_sentences('english-french-train.pkl')\n",
    "test = load_clean_sentences('english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare french tokenizer\n",
    "fre_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "fre_length = max_length(dataset[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "trainX = encode_sequences(fre_tokenizer, fre_length, train[:, 1])\n",
    "testX = encode_sequences(fre_tokenizer, fre_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save my NN model to YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://towardsdatascience.com/saving-and-loading-keras-model-42195b92f57a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.349723756313324"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(trainX, trainY, verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.71%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(trainX, trainY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next repeat this for each source phrase in a dataset and \n",
    "#-> compare the predicted result to the expected target phrase in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from #https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "src=[irezvous], target=[will you go], predicted=[will you go]\n",
      "src=[vous manquetil], target=[do you miss it], predicted=[do you miss it]\n",
      "src=[je deteste attendre], target=[i hate to wait], predicted=[i hate to wait]\n",
      "src=[la tete me tournait], target=[i was dizzy], predicted=[i was dizzy]\n",
      "src=[il loucha], target=[he squinted], predicted=[he squinted]\n",
      "src=[donnezlemoi], target=[give it to me], predicted=[give it to me]\n",
      "src=[ils ont dit non], target=[they said no], predicted=[they said no]\n",
      "src=[tenez], target=[here it is], predicted=[here it is]\n",
      "src=[qui a besoin de ca], target=[who needs that], predicted=[who needs that]\n",
      "src=[puisje me joindre a vous], target=[can i join you], predicted=[may i join you]\n",
      "BLEU-1: 0.882012\n",
      "BLEU-2: 0.834714\n",
      "BLEU-3: 0.730515\n",
      "BLEU-4: 0.408215\n",
      "test\n",
      "src=[cela coule de source], target=[its obvious], predicted=[it amazed me]\n",
      "src=[tom a pali], target=[tom went pale], predicted=[tom fired]\n",
      "src=[jai ete expulsee], target=[i got expelled], predicted=[i was naive]\n",
      "src=[donnelui du temps], target=[give him time], predicted=[what your time]\n",
      "src=[tom est daccord], target=[tom agrees], predicted=[tom approves]\n",
      "src=[je lai vu], target=[ive seen it], predicted=[i saw it]\n",
      "src=[estce inoffensif], target=[is it safe], predicted=[is it]\n",
      "src=[personne ne peut le dire], target=[no one can say], predicted=[no one say]\n",
      "src=[tu peux te joindre], target=[you can come], predicted=[you can go]\n",
      "src=[je ne lai pas fait], target=[i didnt do it], predicted=[i did for it]\n",
      "BLEU-1: 0.567717\n",
      "BLEU-2: 0.450994\n",
      "BLEU-3: 0.368361\n",
      "BLEU-4: 0.177018\n"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    " \n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    " \n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    " \n",
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    " \n",
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "\n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, eng_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    " \n",
    "# load datasets\n",
    "dataset = load_clean_sentences('english-french-both.pkl')\n",
    "train = load_clean_sentences('english-french-train.pkl')\n",
    "test = load_clean_sentences('english-french-test.pkl')\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "# prepare french tokenizer\n",
    "fre_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "fre_length = max_length(dataset[:, 1])\n",
    "# prepare data\n",
    "trainX = encode_sequences(fre_tokenizer, fre_length, train[:, 1])\n",
    "testX = encode_sequences(fre_tokenizer, fre_length, test[:, 1])\n",
    " \n",
    "# load model\n",
    "model = load_model('model.h5')\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-193c8672be89>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its obvious</td>\n",
       "      <td>to chicken he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tom went pale</td>\n",
       "      <td>tom else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got expelled</td>\n",
       "      <td>i in house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>give him time</td>\n",
       "      <td>very as lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom agrees</td>\n",
       "      <td>tom sudden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ive seen it</td>\n",
       "      <td>i help to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is it safe</td>\n",
       "      <td>is to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no one can say</td>\n",
       "      <td>like had still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you can come</td>\n",
       "      <td>you want this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i didnt do it</td>\n",
       "      <td>i go some to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are you young</td>\n",
       "      <td>have you who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>im old enough</td>\n",
       "      <td>the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>should i come</td>\n",
       "      <td>yesterday i his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>go home</td>\n",
       "      <td>this no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>youre lazy</td>\n",
       "      <td>that speak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual          predicted\n",
       "0      its obvious    to chicken he  \n",
       "1    tom went pale        tom else   \n",
       "2   i got expelled       i in house  \n",
       "3    give him time      very as lot  \n",
       "4       tom agrees      tom sudden   \n",
       "5      ive seen it        i help to  \n",
       "6       is it safe           is to   \n",
       "7   no one can say   like had still  \n",
       "8     you can come    you want this  \n",
       "9    i didnt do it      i go some to \n",
       "10   are you young     have you who  \n",
       "11   im old enough         the day   \n",
       "12   should i come  yesterday i his  \n",
       "13         go home         this no   \n",
       "14      youre lazy      that speak   "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>grab that</td>\n",
       "      <td>they're don't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>whose is it</td>\n",
       "      <td>him is to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>is it helping</td>\n",
       "      <td>want to fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>dont shoot</td>\n",
       "      <td>my against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>are we done</td>\n",
       "      <td>have do last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>keep on trying</td>\n",
       "      <td>us careful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>stop tom</td>\n",
       "      <td>i've some tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>keep writing</td>\n",
       "      <td>into crying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>be content</td>\n",
       "      <td>was guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>i need more</td>\n",
       "      <td>i did enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>i have no food</td>\n",
       "      <td>i when like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>i also went</td>\n",
       "      <td>i told has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>let go of it</td>\n",
       "      <td>hear for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>are you tired</td>\n",
       "      <td>have you say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>catch tom</td>\n",
       "      <td>bad tom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual         predicted\n",
       "379       grab that  they're don't   \n",
       "376     whose is it       him is to  \n",
       "465   is it helping    want to fool  \n",
       "977      dont shoot     my against   \n",
       "349     are we done    have do last  \n",
       "580  keep on trying     us careful   \n",
       "743        stop tom   i've some tom  \n",
       "885    keep writing    into crying   \n",
       "660      be content        was guy   \n",
       "284     i need more    i did enough  \n",
       "110  i have no food     i when like  \n",
       "71      i also went      i told has  \n",
       "593    let go of it       hear for   \n",
       "856   are you tired    have you say  \n",
       "813       catch tom        bad tom   "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
