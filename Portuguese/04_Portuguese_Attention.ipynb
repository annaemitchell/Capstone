{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation: Portuguese with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Implementing seq2seq NMT using Bahdanau's Attention mechanism. \n",
    "#### - Implementing code in tensorflow 2.0 using GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # trying tensorflow this way, using version 2.0 to check if this helps model \n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"port.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125722</th>\n",
       "      <td>I noticed that I was being observed.</td>\n",
       "      <td>Eu notei que estava sendo observado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>We'll be heroes.</td>\n",
       "      <td>Seremos heróis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115571</th>\n",
       "      <td>Do you have any trouble with that?</td>\n",
       "      <td>Você tem algum problema com isso?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86586</th>\n",
       "      <td>You need to wash your hands.</td>\n",
       "      <td>Você precisa lavar as suas mãos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128692</th>\n",
       "      <td>Didn't you know Tom was still single?</td>\n",
       "      <td>O Tom não sabia que você ainda estava solteira?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       source  \\\n",
       "125722   I noticed that I was being observed.   \n",
       "13792                        We'll be heroes.   \n",
       "115571     Do you have any trouble with that?   \n",
       "86586            You need to wash your hands.   \n",
       "128692  Didn't you know Tom was still single?   \n",
       "\n",
       "                                                 target  \n",
       "125722             Eu notei que estava sendo observado.  \n",
       "13792                                   Seremos heróis.  \n",
       "115571                Você tem algum problema com isso?  \n",
       "86586                  Você precisa lavar as suas mãos.  \n",
       "128692  O Tom não sabia que você ainda estava solteira?  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "lines_raw= pd.read_table(data_path,names=['source', 'target'])\n",
    "lines_raw.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and preprocess the source and target sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code help from the following sources:\n",
    "# https://www.researchgate.net/publication/337459762_Neural_Machine_Translation_with_Attention_Based_on_a_New_Syntactic_Branch_Distance\n",
    "# https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16534/15733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= sentence.strip()\n",
    "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence=  'start_ ' + sentence + ' _end'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ bring me another beer . _end\n",
      "b'start_ traga-me outra cerveja . _end'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"Bring me another beer.\"\n",
    "port_sentence = u\"traga-me outra cerveja.\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(port_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://stackoverflow.com/questions/63268582/bahdanaus-attention-in-neural-machine-translation-with-attention|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "  \n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  #print(lines)\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  print(path)\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "port.txt\n",
      "start_ who wants to talk to me ? _end\n",
      "start_ quem quer falar comigo ? _end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size=60000\n",
    "source, target = create_dataset(data_path, sample_size)\n",
    "print(source[-1])\n",
    "print(target[-1])\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize source and target sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://www.mathworks.com/help/deeplearning/ug/sequence-to-sequence-translation-using-attention.html\n",
    "#code hep from https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjlmPmzmK_sAhWtc98KHRLJBj8QFjAfegQIHhAC&url=https%3A%2F%2Fcontent.sciendo.com%2Fview%2Fjournals%2Fpralin%2F109%2F1%2Farticle-p39.xml%3Flanguage%3Den&usg=AOvVaw1b6pbDH-bou491Uy0PL_M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "  return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "source_sentence_tokenizer.fit_on_texts(source)\n",
    "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
    "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "target_sentence_tokenizer.fit_on_texts(target)\n",
    "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
    "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n",
    "print(len(target_tensor[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "max_target_length= max(len(t) for t in  target_tensor)\n",
    "print(max_target_length)\n",
    "max_source_length= max(len(t) for t in  source_tensor)\n",
    "print(max_source_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80/20 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 48000 12000 12000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_tensor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> start_\n",
      "5 ----> tom\n",
      "6512 ----> deciphered\n",
      "11 ----> the\n",
      "4013 ----> code\n",
      "3 ----> .\n",
      "2 ----> _end\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> start_\n",
      "4 ----> tom\n",
      "11341 ----> decifrou\n",
      "7 ----> o\n",
      "5967 ----> código\n",
      "3 ----> .\n",
      "2 ----> _end\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert( target_sentence_tokenizer, target_train_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since dataset is big, create dataset in memory to be efficient \n",
    "# using tf.data.Dataset.from_tensor_slices() method to get slices of the array in the form of an object.\n",
    "\n",
    "# dataset will be created in batches of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code help from https://iopscience.iop.org/article/10.1088/1742-6596/1237/5/052020/pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(source_train_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 11]), TensorShape([64, 17]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we are iterate through all the elements in the dataset. \n",
    "# The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the sequence to sequence model with Bahdanau’s Attention using Gated Recurrent Unit(GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://devmesh.intel.com/projects/neural-machine-translation-using-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the encoder takes the input as the source tokens, passes them to an embedding layer for the dense\n",
    "# -> representation of the vector, which is then passed to the GRU\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=1228&context=creativecomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 11, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "#test the encoder class and print the dimensions of the encoders output and hidden state \n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Bahdanau Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://pubmed.ncbi.nlm.nih.gov/31902775/\n",
    "#code help from https://talbaumel.github.io/blog/attention/\n",
    "#code help from https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/BahdanauAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Bahdanau attention layer with ten units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://www.coursera.org/lecture/attention-models-in-nlp/training-an-nmt-with-attention-hy9Vc\n",
    "#code help from https://labs.eleks.com/2019/06/neural-machine-translation-attention-mechanism.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 11488)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the optimzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16534/15733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://www.mathworks.com/help/deeplearning/ug/sequence-to-sequence-translation-using-attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow keeps track of every gradient for every computation on every tf.Variable\n",
    "#To train, we use gradient tape to control the areas of code where we need gradient information.\n",
    "#For seq2seq with the Attention mechanism, we calculate the gradient for the Decoder’s output only.\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the encoder-decoder with attention using multiple epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting with 2 epochs\n",
    "#will use more when transfering to cloud computing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 loss 3.5316121578216553\n",
      "Epoch 1 Batch 100 loss 1.6323176622390747\n",
      "Epoch 1 Batch 200 loss 1.4525972604751587\n",
      "Epoch 1 Batch 300 loss 1.4221516847610474\n",
      "Epoch 1 Batch 400 loss 1.2433125972747803\n",
      "Epoch 1 Batch 500 loss 1.2710511684417725\n",
      "Epoch 1 Batch 600 loss 1.0172932147979736\n",
      "Epoch 1 Batch 700 loss 0.9961529970169067\n",
      "Epoch 1 Loss 1.3129\n",
      "Time taken for 1 epoch 1156.4184429645538 sec\n",
      "\n",
      "Epoch 2 Batch 0 loss 0.8583486080169678\n",
      "Epoch 2 Batch 100 loss 0.7834741473197937\n",
      "Epoch 2 Batch 200 loss 0.7327104210853577\n",
      "Epoch 2 Batch 300 loss 0.6641588807106018\n",
      "Epoch 2 Batch 400 loss 0.6050483584403992\n",
      "Epoch 2 Batch 500 loss 0.6940865516662598\n",
      "Epoch 2 Batch 600 loss 0.5418525338172913\n",
      "Epoch 2 Batch 700 loss 0.5925803780555725\n",
      "Epoch 2 Loss 0.6864\n",
      "Time taken for 1 epoch 1160.9709219932556 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
    "   \n",
    "      \n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Inferences for the test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making inferences is similar to training except that we do not know the actual work that is used in \"Teacher\n",
    "Forcing\", so we pass the predicted word from the previous time step to the Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://iopscience.iop.org/article/10.1088/1742-6596/1237/5/052020/pdf\n",
    "#code help from https://devmesh.intel.com/projects/neural-machine-translation-using-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  #print(sentence)\n",
    "  #print(source_sentence_tokenizer.word_index)\n",
    "\n",
    "  inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_source_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to plot the Attention weights between the source words and target words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=1228&context=creativecomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the source sentence to target sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make a call to the evaluate function, which creates the Encoder, Decoder and Attention layer\n",
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "  \n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe3e0eeaee0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The attention plot for the translated sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ i like cake . _end\n",
      "Predicted translation: eu gosto de bolo . _end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'I like cake.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ i am ready for anything . _end\n",
      "Predicted translation: estou pronto para o trabalho . _end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'I am ready for anything.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ i like beer . _end\n",
      "Predicted translation: eu gosto de cerveja . _end \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAJgCAYAAADMAMqBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf2UlEQVR4nO3de7jlB13f+88XJsmYpNECFlGupSCiFJAAcqqkFIX4qKhA+1hFEdCxokcBOaJYgaocCsYjCnpC2sOlIopii9yqXKQEfeCAihAIHElCjIhykVC5JDEJ3/PHWlN3dnYmM5P5zm+vPa/X8+xnz/r91l7ru3+5zHv/bru6OwAAE2629AAAwN4lNACAMUIDABgjNACAMUIDABgjNACAMUIDABgjNACAMUJjQ1XVBVV1u6XnAIBDERqb645JTlp6CAA4FKEBAIwRGgDAGKEBAIwRGgDAmH1LDwAArFTV7Q/3ud192eQsx4rQ2GWq6nuSvLy7r9q2/OQk39Hd/2W96AeSfPR4zwfAqEuT9GE+9+aDcxwz1X243w/HQ1Vdm+Q23f2xbctvmeRj3b0R/2IBcOSq6j5bHt41yXOSnJvkbetlD8jqB82ndPdvHOfxjorQ2GWq6vNJbt3dH9+2/N5J3tTdt1hmMiBJquqkJH+Z5MHd/b6l52Hvqqq3JHled79i2/JHJvnR7v66ZSY7Mg6d7BJVdUFWu8s6yVuq6potq2+e5A5JXrfEbMA/6O6rq+rqHP7ubTha90vynh2WvyfJfXZYvisJjd3jYLF+VZLXJvnMlnV/n9Vxu985zjMBO3tekp+sqsd09zU3+mw4OpcmeXySJ2xb/vgkf3HcpzlKDp3sIlW1L6tjb6/s7r9aeh5gZ1X16iRnJbkiyXuTfHbr+u5+2BJzsbdU1dlJ/ltWUfH29eL7Z/UrKB7e3f99odGOiNDYZarqyiR36+5Ll54F2FlVvehQ67v7McdrFva2qrptVnsw7pakklyY5Nzu/stFBzsCQmOXqar/N8lPdfcbl54FAG4qobHLVNU3JvmPSZ6e5E9y/V2yn1xiLuD6qurMJHdO8pru/mxVnZbkKudtcKxU1alJ7pXkn2Tb3by7+78uMtQREhq7zPry1oO2/sOpJO0+GrC8qrp1klcluW9W/53epbsvqaoXJLmyu3900QHZE6rq65P8RpJb7rB6Y/4+cNXJ7vOgpQfgxFJV+5N8c1Y/mb+guz9VVXdOcrk9aDfoF5P8TVZ/AWy9DfRvZ3VFChwLv5TVVYhP7e6PLD3M0bJHA05gVfXPkrwhyT9K8kVJ7rr+yfycJF/U3d+36IC7VFV9NKsbdr23qj6d5J7r7XanJO/t7tMWHpE9oKo+m+Sfd/fFS89yU9ijsUtV1ZcmuX2Sk7cu7+7zl5mIPeq5WYXGDyb51Jblr0pyyCsrTnBfkNX9bbb74iRXHudZ2Lv+KMmXJxEaHDvrwHhZkgdmdey3ct1zNTbimBwb439L8jXdfW1VbV1+WZIvXWakjXB+ku9N8tT1466qmyd5SpI3LTUUe865Sc5Z/71wQZKrt67s7j9dZKojJDR2n+cmuTbJ3ZO8M8nZSW6d5GeSPHHBudi7Ttph2e2T/M/jPcgG+fGsflXAfZOckuQXknxlki9M8i+WHIw95eAdo8/bYV1nQ37wFBq7z1lJvqm7P1BVneTj3f1HVXVVkp/Najc3HCuvT/KkJI9bP+6qOiPJf8jqJDR20N0XVtU9srqR0lVJ9md1IuivdPdfLzoce8mdlh7gWHAy6C5TVX+X1ck/l1bVpUke1d1/uD7J7H3dfeqyE7KXrHfJvnn98J8meVeSf5bko0keuP23CAMcqZvd+FM4zj6Q1a1mk+TPkvy7qrpDkh9K4vefcEytL5m7V5JnJ3lBkj/O6rDAV4uMQ6uqe1TV86vqdVV1m/Wyb6uqey89G3tHVX1jVb2mqi6sqtutl31fVT146dkOl9DYfX4pyZes//wzSR6S5JKsdtE+9Ya+CI5GVX1/d1/R3S/s7h/u7sd393/u7iuq6tyl59utquohWZ1D9WVJHpzVVSjJ6l4kT19qLvaWqvquJL+V5INZHUY5eD7VzbP6gWAjOHSyy61vP3u3JJd19yeWnoe9paouT/J93f0725afl+Sh3X2HZSbb3da/k+gl3f2r2+6jcZ8kr+5uV+xwk1XVu5M8q7t/c9u/Z/dM8vruvvXCIx4WezR2map62joukiTd/bn1JUyfraqnLTgae9Mjk7xw627YdWScHXepPZSvTPK6HZZ/MsktjvMs7F13SfK2HZZ/JskZx3mWoyY0dp+nJzl9h+Wnxi5ZjrHuflOSxyZ5RVXdv6r+U5KHJvmX3X3JstPtapdnddhku69O8uHjPAt710eS3HWH5Q/MBt3Ey+Wtu8/2G3QddO+sflqCY6q7f6eqbpHVTaj+OslZ3X3pslPtei9L8vNV9W+y+u91X1WdleScuKMqx855SX65qg7+KoDbVdXXJXlOkmcsNtURco7GLrE+/tZJTkvyuVz/bqD7k5zb3T+0wHjsIVX1yzew6tuSvDvJhw4u6O4fOS5DbZiqOinJi5N8R1Y/HHw+qz3Ev57ke7v72uWmYy+pqmdmdbPG/etFVyU5p7t/estzbpvkI939+R1eYnFCY5eoqkdn9T+sFyZ5Qq57V8a/T3Jpd+90rA6OSFW9+caflWT1a6j/1egwG66q/mmSr83qB4O3dfdFC4/EHrQ+b+/uWcXshd39mW3r/y7JvXbr4U6HTnaJ7n5JklTVaUnO7+4L1o+/Icmjk7yvqt7hJyVuqu52kucxUFVPyOquqgfP1fhIVf1fSZ7bfoLjGOruz2V1j5sbUodYtzihsfs8KsnfJrlgvTvslUnektUNu85I8pMLzgYkqarnJDmQ5OfzD1cFPCDJ05LcJht0jwOY5tDJLlNVn0pyv+7+86p6YpKHdfeDqupBSV7U3XdcdkI2XVW9Kqtb2//d+s83qLsfdpzG2ihV9ckkB7r7FduWPzLJC7r7lstMxolo6z02lp5lJ/Zo7D43z+qcjGR1x8GD1+pfnNVvcYWb6m/zDycbfzI7X+XEjXvPDSxz2wDYwh6NXaaq3pbVZYavyeo3a96vuy+oqgck+a3uvt2iAwKpqudm9f/PH922/BeT3NzVOhxPTgblSD0lq/MynpzVLY4vWC9/WJJ3LDbVLuUwwJG7se20RXf3t44Os0G2XRa8L8mjquqhSd6+Xnb/JF+a1SWuHIGqen+Su3S3v5OOjpNBOXzdfX5VfXGSM7r78i2rXpDV/TW4rq2HAf52yUE2iO10dO6x7fGfrD8f/H0wf7P+uFs4Ur+SxHktR+/uWd1FdFdy6AQAGOOkJQBgjNAAAMYIjQ1QVQeWnmHT2GZHx3Y7crbZ0bHdjs4mbjehsRk27l+sXcA2Ozq225GzzY6O7XZ0Nm67CQ0AYIyrTtZOrlN6f05beowdXZ2rclJOWXqMjWKbHR3b7cjZZkfHdjs6u3m7fTqXf6K7v3j7cvfRWNuf03L/evDSYwDARnpjv+Ivdlru0AkAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjNio0auXHq+riqrqiqi6oqket192xqrqqztz2NV1Vj1xmYgA4se1beoAj9HNJHpnkh5L8f0kekOQ/VdXlSd635GAAwPVtTGhU1WlJnpTkId391vXiD1XV/bIKj8cvNhwAsKONCY0kd0+yP8nvVVVvWX5SkkuP5gWr6kCSA0myP6fe1PkAgG02KTQOnk/yLUku27bu6iQH46MOLqyqkw71gt19XpLzkuSMukUf6rkAwJHbpNC4MMlVSe7Q3X+wfWVVfcH6j7fZsvhex2MwAGBnGxMa3f3pqjonyTlVVUnOT3J6kq9J8vnuPq+q3p7kKVV1cZIvTPKs5SYGADbq8tYkP53kGUmenNVVJm9I8ogkH1qvf+z68zuTvCDJvz/O8wEAW2zMHo0k6e5O8rz1x07r35/kX2xbXDs9FwCYt2l7NACADSI0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAx+5YeYLeoqtxs//6lx9gsJ5209AQb6T5v/dTSI2yk85/+gKVH2Din/9HFS4+wka79pP9Gj8q1Oy+2RwMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxQgMAGCM0AIAxGxsaVdVV9cil5wAAbtjGhgYAsPuNhUZVnVZV/6WqPlNVH62qn6yq11TVi9fr/3FVvaSqLq+qK6rqjVX1lVu+/gur6teq6mNVdWVVXVJVT1ivu3T9tN9e79m4dMvX/UBVXVRVf7/+/P1T3yMAcGiTezR+IclZSb49yb9Kcs8kX7dl/YuT3D/Jtya5X5LPJfm9qvqC9fqfS3KPJN+c5G5JHpvkr9br7rv+/P1JbnPwcVV9e5LnJ3lukq9K8ktJfrWqvuWYf3cAwI3aN/GiVXV6VmHwPd39hvWyxyX58PrPd0nysCRndff562XfneSyJN+V5D8nuUOSd3X3O9Yve+nB1+/uj1dVknyqu/9my1s/Ocmvdffz14//vKruk+QpSV69w5wHkhxIkv112k3/xgGA65jao3HnJCclORgJ6e7PJnnv+uFXJPl8krdtWf8/k1yQ5O7rRf93kn9TVe+uqnOq6qzDeN+vSPJH25b94ZbXvI7uPq+7z+zuM0/OKYfx8gDAkZgKjVp/7htZv5NOku7+71nt1Tgnya2SvLaqXnQY773Te97QHADAoKnQuCjJ1Vmde5EkqapTszpvIkkuXL/3A7asPyOrczIuPLisuz/R3b/W3d+b5HFJHl1VB3c9XJ3k5tve9/1Jvnbbsq/d+poAwPEzco5Gd3+mql6Y5NlV9Ykkf53k32cVF93dH6yq303ygvV5Ep9K8swkf5fkZUlSVT+T5E+TvG8958OTXNLdV63f5tIkD66qtyS5qrsvT/LzWV2J8idJXp/k7KzO+Xj4xPcJABza5FUnT07y1iSvSvLmJO9J8sdJrlyvf0xW53C8av351CRnd/cV6/VXZRUf787qvIt/lGTr1SM/luRBSf4yybuSpLtfmeR/T/LErPZi/GiSx3f39U4EBQDmjezRSFZ7NZJ89/oj60MeT0jyuvX6y5M8+hBf/8ysQuOG1r86O1xJ0t3nJjn3pswOABwbY6FRVffO6iqQd2S1N+Ip688vn3pPAGB3GQuNtScl+fIk1yT5syQP7O4PD78nALBLTB46eVeSM6deHwDY/fxSNQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMbsW3qA3aKT9LWfX3qMzXLNFUtPsJFe+Rtft/QIG+naR3166RE2zukX3WrpETbTJz+19AR7ij0aAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjNn40Kiq11TVi5eeAwC4vo0PDQBg9xIaAMCYjQqNqjq1ql5cVZ+pqo9W1VO3rT+5qp5dVR+uqs9W1Tur6qFLzQsAJ7qNCo0k5yT5hiSPSPLgJPdO8sAt61+U5Kwk35nkHklekuTVVXXP4zwnAJBk39IDHK6qOj3J45I8trt/f73sMUk+vP7znZP82yR37O7L1l/2/Kr6+iQ/kOTxO7zmgSQHkmR/Th3/HgDgRLMxoZHkzklOTvK2gwu6+zNVdcH64VcnqSQXVtXWrzslyR/s9ILdfV6S85LkjJvdsgdmBoAT2iaFRt3I+psl6ST3TXL1tnVXjEwEABzSJoXGRVkFxNckuSRJquq0JF+V5OIk78oqRr6ku9+81JAAwD/YmNBYHyb5f5I8u6o+nuQjSZ6W5Obr9X9eVb+e5MVV9WNJ/jTJLZL8yySXdPd/XWZyADhxbUxorD05yWlJ/luSzyV53vrxQY9J8lNJnpPktkk+meQdSezhAIAFbFRodPdnk3zP+mOn9Vcnecb6AwBY2KbdRwMA2CBCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDFCAwAYIzQAgDH7lh5g1+hOX3P10lNslu6lJ9hIt/2Fdyw9wka669tr6RE2zlu+4b5Lj7CRbnPRpUuPsJmu3XmxPRoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwBihAQCMERoAwJiNDo2q+h9V9fyl5wAAdrZv6QFuoocnuXrpIQCAnR330KiqfUmu7e6+qa/V3Z88BiMBAEMO69BJrfxYVX2wqq6qqg9X1bPW676sqn6zqi5ff7y2qu6y5WufUVXvrarvraqLk1yV5Eeq6qPr6Nj6Pi+rqt/d8vhbqupPqurKqvpQVT2zqk7esv46h06q6lFV9c6q+nRVfayqfruqvuzoNw8AcFMc7jka/2eSn07yrCRfmeRfJ/nLqjo1yZuTXJnkrCQPSPLXSd64XnfQnZJ85/rr7pnkZUm+KMnXH3xCVZ2W5FuTvHT9+KFJfj3J89fv+dgkj1zPckNOTvL09Xt8c5JbJfmNw/weAYBj7EYPnVTV6UmemOQJ3f3C9eKLkrytqh6bpJI85uChkKr6gSQfy+ov+t9aP//kJN/d3R/d8rqvS/JdSX5vvejbk1yT5NXrxz+V5Oe7+0XrxxdX1VOSvLSq/o+dDr1smS9JLqmqH0zy/qq6bXd/+Ma+VwDg2DqcczTunuSUJG/aYd19stpb8emq2rr81CR33vL4w1sjY+2lSV5cVad29+eyio5XdPeVW177fuu4OOhmSb4gyZdktefkOqrqq7Pao3GvJLfIKoKS5PZJrhcaVXUgyYEk2Z9Tt68GAG6iwwmNOsS6myX5syTfscO6rSdqfnaH9a/Jag/Gt1bVm7I6jPKQba/9H5L89g5f+/HrDbk69PL7Sd6Y5Luz2qtyqyRvzWqPyvV093lJzkuSM+oWN/nkVADgug4nNC7M6gTOByf54LZ1f5rk3yb5RHd/6kjeuLuvqqpXZLUn41ZJ/ibJW7a99t26+6LDfMm7rV/nqd39oSSpqocfyUwAwLF1o6HR3Z+uql9K8qyquirJ+UlumdWhjZckeXKS362qpyW5LMntsjqp89zu3h4m2700qz0Qd0rysu7+/JZ1P5PkNVX1F1md63FNkq9Kcr/u/vEdXuuyrILoh6vqV5J8RZKfvbHvDwCYc7hXnfxkkmdndeXJ+5P8TpLbrs+teGCSS7I6xPGBrOLjHye5/DBe9/wkf5XVeSAv3bqiu38/yTcleVCSd6w/fiKroLie7v54kkcn+bas9sI8PcmTDvP7AwAGHNYNu9Z7Gv7j+mP7uo8mecwhvvYZSZ5xA+s6yR0P8bWvT/L6Q4x2SpLPbHn+y5O8fNtzDnWOCQAwaCN/10lVnVJVZ2Z1f433Lj0PALCzjQyNJN+Y5A+yuufG9j0YAMAusZG/VK27X5nkjKXnAAAObVP3aAAAG0BoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMEZoAABjhAYAMGbf0gPsKt1LT8AJoK+5ZukRNtJF33nnpUfYOO/+H7+69Agb6ZtefvbSI2ymj+y82B4NAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxggNAGCM0AAAxuxbeoAlVdWBJAeSZH9OXXgaANh7Tug9Gt19Xnef2d1nnpRTlh4HAPacEzo0AIBZQgMAGLPnQ6OqfriqPrD0HABwItrzoZHkVkm+fOkhAOBEtOdDo7uf0d219BwAcCLa86EBACxHaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBm39IDAByOaz94ydIjbJyvfc/Dlx5hI33sR2699Aib6Sd2XmyPBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGOEBgAwRmgAAGP2dGhU1ZlV1VV1x6VnAYAT0Z4ODQBgWUIDABizK0KjVn68qi6uqiuq6oKqetSW9XdcHwJ5RFW9oao+V1UXVtU3bHuds6vqA1V1ZVW9Ncldj/s3AwD8L7siNJL8XJLHJfmhJHdP8qwkL6iqb9r2vGcm+eUk90zyziS/WVWnJ0lV3S7JK5O8Icm9kjwvyXOOy/QAwI72LT1AVZ2W5ElJHtLdb10v/lBV3S+r8Hjtlqf/Yne/ev11T03yPVlFxR8m+cEklyX5ke7uJB+oqrsm+dlDvPeBJAeSZH9OPabfFwCwC0Ijqz0Y+5P8XlX1luUnJbl023Pfs+XPH1l//ifrz1+R5O3ryDjobYd64+4+L8l5SXJG3aIP9VwA4MjthtA4ePjmW7LaI7HV1Tf0uLu7qrZ+fY1MBwActd0QGhcmuSrJHbr7D27i6zyiqmrLXo2vucnTAQBHbfHQ6O5PV9U5Sc6p1S6K85OcnlUkfH59eONwnJvkx5I8t6p+Nck9kvy7iZkBgMOzW646+ekkz0jy5CTvy+rKkUck+dDhvkB3X5bk4UnOTvLuJE9M8hPHelAA4PAtvkcjWZ1vkdXlqM+7gfWXZodzMLq7tj1+ba57lUqS/PqxmRIAOFK7ZY8GALAHHZc9GlV1+6xO1rwhd18f+gAA9pDjdejkI1ndWOtQ6wGAPea4hEZ3X5PkouPxXgDA7uEcDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgjNAAAMYIDQBgzL6lBwA4LN1LT7BxTjv7kqVH2Eh3iu12NC6+geX2aAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBGaAAAY4QGADBm39IDLKmqDiQ5kCT7c+rC0wDA3nNC79Ho7vO6+8zuPvOknLL0OACw55zQoQEAzBIaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjBEaAMAYoQEAjKnuXnqGXaGqPp7kL5ae4wbcKsknlh5iw9hmR8d2O3K22dGx3Y7Obt5ud+juL96+UGhsgKr64+4+c+k5NoltdnRstyNnmx0d2+3obOJ2c+gEABgjNACAMUJjM5y39AAbyDY7OrbbkbPNjo7tdnQ2brs5RwMAGGOPBgAwRmgAAGOEBgAwRmgAAGOEBgAw5v8HdLZWm8t0W1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'I like beer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
